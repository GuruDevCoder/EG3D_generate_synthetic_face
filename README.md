# Generate synthetic face data using EG3D
This repository, generates photorealistic face synthetic data, as well as the the corresponding depthmaps and 3D face structure/mesh using plug & play notebooks inspired by [EG3D](https://github.com/NVlabs/eg3d). In essence, EG3D is leveraged to generate synthetic face data and extract the respective face meshes, generated by EG3D or extarcted from the corresponding depthmaps. The generated EG3D .obj meshes have higher facial detail, in contrast to the meshes extracted from the underlying 128x128 depthmaps. 
Below you can find the relavant notebooks:
| Description      | Link |
| ----------- | ----------- |
| Generate EG3D face data (image, depthmap and 3D .obj)| [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cantonioupao/generate-synthetic-face-data/blob/main/colab_notebooks/eg3d.ipynb)|
| Visualize synthetic face mesh | [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cantonioupao/generate-synthetic-face-data/blob/main/colab_notebooks/visualize_mesh.ipynb)|

This repository is inspired by the EG3D [paper]() and uses the codebase from [EG3D](https://github.com/NVlabs/eg3d). Please refer to the [project's webpage](https://arxiv.org/pdf/2112.07945.pdf) for more information.


By leveraging EG3D, the synthetic training set for training our depth & latent code regressor models was achieved. The training set consists of 50,000 samples of high-quality face images (.png) (512x512), the corresponding depthmaps(.png) (128x128), the 3D meshes (.obj), the EG3D latent code (.npy) and the corresponding camera parameters (.npy) (25,1) (16 extrinsic and 9 instrinsic parameters). The training dataset, to be generated requires 21 GPU days on a Tesla P100 GPU. The training dataset link can be downloaded using the link [here](https://drive.google.com/drive/folders/1-1T7kHcux_v9rjK6AJ_5uH9n3zuka09E?usp=sharing). The training dataset generated face images, from various viewpoints, to ensure the robustness of the trained models. The various viewpoint categories and the respective dataset percentages are depicted in the image above. 

